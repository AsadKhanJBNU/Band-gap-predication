{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import networkx as nx\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json,pickle\n",
    "from collections import OrderedDict\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import Data_Preprocessing.Graph_Data as gd\n",
    "from Data_Preprocessing.Graph_Data import Molecule_data\n",
    "from models.AttentiveFPModel import AttentiveFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFoldsData():\n",
    "    iy = 0\n",
    "    folds = 5\n",
    "    for fold in tqdm(range(folds)):\n",
    "        df_train = pd.read_csv('New_fold/fold_'+str(iy)+'_'+'x_train.csv')\n",
    "        df_test  = pd.read_csv('New_fold/fold_'+str(iy)+'_'+'x_test.csv')\n",
    "        smiles = df_train['SMILE']\n",
    "        codIds = df_train['CODID']\n",
    "        band_gap = df_train['bgs']\n",
    "        band_gap = band_gap.to_numpy()\n",
    "\n",
    "        smiles_test = df_test['SMILE']\n",
    "        codIds_test = df_test['CODID']\n",
    "        band_gap_test = df_test['bgs']\n",
    "        band_gap_test = band_gap_test.to_numpy()\n",
    "\n",
    "\n",
    "        smile_graph = {}\n",
    "        band_gap_arr = []\n",
    "        smiles_array = []\n",
    "\n",
    "        for i,smile in enumerate(smiles):\n",
    "            g = gd.smile_to_graph(smile)\n",
    "            if g != None:\n",
    "                smile_graph[smile] = g\n",
    "                band_gap_arr.append(band_gap[i])\n",
    "                smiles_array.append(smile)\n",
    "\n",
    "        smile_graph_test = {}\n",
    "        band_gap_arr_test = []\n",
    "        smiles_array_test = []\n",
    "\n",
    "        for i,smile in enumerate(smiles_test):\n",
    "            g = gd.smile_to_graph(smile)\n",
    "            if g != None:\n",
    "                smile_graph_test[smile] = g\n",
    "                band_gap_arr_test.append(band_gap_test[i])\n",
    "                smiles_array_test.append(smile)\n",
    "\n",
    "        train_data = Molecule_data(root='data', dataset='train_data_set_fold_'+str(iy),y=band_gap_arr,\n",
    "                                   smile_graph=smile_graph,smiles=smiles_array)\n",
    "\n",
    "        test_data = Molecule_data(root='data', dataset='test_data_set_fold_'+str(iy),y=band_gap_arr_test,\n",
    "                                   smile_graph=smile_graph_test,smiles=smiles_array_test)\n",
    "\n",
    "        iy+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_Preprocessing/omdb_smile_data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = df['SMILE']\n",
    "codIds = df['CODID']\n",
    "band_gap = df['bgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_gap = band_gap.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFoldsCsv():\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=5,shuffle = True, random_state = 42)\n",
    "    ix = 0\n",
    "    train1 = df\n",
    "    for train_index, test_index in (kf.split(train1)):\n",
    "        print (\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "        X_train,X_test=train1.iloc[train_index], train1.iloc[test_index]\n",
    "        X_train.to_csv('New_fold/fold_'+str(ix)+'_'+'x_train.csv',index=False)\n",
    "        X_test.to_csv('New_fold/fold_'+str(ix)+'_'+'x_test.csv',index=False)\n",
    "        ix+=1\n",
    "    createFoldsData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_file_train = 'data/processed/' + 'test_data_set_fold_'+str(0)+'.pt'\n",
    "processed_data_file_test = 'data/processed/'  + 'train_data_set_fold_'+str(0)+'.pt'\n",
    "if ((not os.path.isfile(processed_data_file_train)) or (not os.path.isfile(processed_data_file_test))):\n",
    "        print('please run create_data.py to prepare data in pytorch format!')\n",
    "        createFoldsCsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:4\"\n",
    "    print(\"cuda:4\")\n",
    "else:  \n",
    "    device = \"cpu\" \n",
    "    print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function at each epoch\n",
    "def train(model, device, train_loader, optimizer, epoch,loss_fn):\n",
    "    #print('Training on {} samples...'.format(len(train_loader1.dataset)))\n",
    "    model.train()\n",
    "    Loss = []\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x.float(), data.edge_index,data.batch)\n",
    "        loss = loss_fn(output, data.y.view(-1, 1).float().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        Loss.append(loss.item())\n",
    "    nploss = np.asarray(Loss)\n",
    "    avg_loss = np.average(nploss)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(model, device, loader,loss_fn):\n",
    "    model.eval()\n",
    "    total_loss=total_example=0\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data.x.float(), data.edge_index,data.batch)\n",
    "            \n",
    "            loss = loss_fn(output, data.y.view(-1, 1).float().to(device))\n",
    "            total_loss+=loss\n",
    "            total_example+=1\n",
    "    return total_loss/total_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR = 0.005\n",
    "LR = 9.797464088146652e-05\n",
    "#LR = 0.0028894537419258915\n",
    "LOG_INTERVAL = 20\n",
    "NUM_EPOCHS = 3000\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ret = []\n",
    "best_mse = 0.80\n",
    "best_ci = 0\n",
    "best_epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "results = []\n",
    "best_mae_arr = []\n",
    "\n",
    "for fold in tqdm(range(folds)):\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    mae_arr = []\n",
    "    patience = 16\n",
    "    trigger_times = 0\n",
    "    the_last_loss = 100\n",
    "    \n",
    "    model_file_name = 'saved_models/model_' +  str(fold) +  '.model'\n",
    "    result_file_name = 'result_' + str(fold) +  '.csv'\n",
    "    \n",
    "    train_data = Molecule_data(root='data', dataset='train_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "    test_data = Molecule_data(root='data', dataset='test_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "    \n",
    "    TRAIN_BATCH_SIZE = 17\n",
    "    \n",
    "    train_loder   = DataLoader(train_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "    test_loder  = DataLoader(test_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "    model = AttentiveFP(in_channels=114, hidden_channels=292, out_channels=1,\n",
    "                    num_layers=3, num_timesteps=2,\n",
    "                    dropout=0.047352327938708194).to(device)\n",
    "    best_ret = []\n",
    "    \n",
    "    model = model.cuda(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    best_mae = 0.00\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss=train(model, device, train_loder, optimizer, epoch+1,loss_fn)\n",
    "        test_loss = predicting(model, device, test_loder,loss_fn)\n",
    "        \n",
    "        print('Epoch% d: Train mae: %2.5f\\t val mae: %2.5f\\t'\n",
    "          %(epoch, train_loss,test_loss.item()))\n",
    "        \n",
    "        ret = [epoch,train_loss,test_loss.item()]\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(test_loss.item())\n",
    "        \n",
    "        # Early stopping\n",
    "        the_current_loss = test_loss.item()\n",
    "        \n",
    "        best_ret.append(ret)\n",
    "        \n",
    "        if the_current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            print('trigger times:', trigger_times)\n",
    "            \n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "        else:\n",
    "            ret = [epoch,train_loss,test_loss.item()]\n",
    "            trigger_times = 0\n",
    "            best_mae = the_current_loss\n",
    "            the_last_loss = the_current_loss\n",
    "            \n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "\n",
    "    results.append(best_ret)\n",
    "    best_mae_arr.append(best_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_float = \"{:.2f}\".format(best_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(format_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resSt = results[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_val = resSt[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "for fold in range(folds):\n",
    "    train_loss_arr = []\n",
    "    test_loss_arr = []\n",
    "    for res in results[fold]:\n",
    "        train_loss_arr.append(res[1])\n",
    "        test_loss_arr.append(res[2])\n",
    "        \n",
    "    print(len(train_loss_arr))\n",
    "    print(len(test_loss_arr))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    ax.WindowState = 'maximized';\n",
    "\n",
    "    format_mae = \"{:.2f}\".format(best_mae_arr[fold])\n",
    "    \n",
    "  #  ax.plot([e for e in range(1,len(train_loss_arr) + 1)], train_loss_arr, label=\"train_loss\")\n",
    "    ax.plot([e for e in range(1,len(test_loss_arr) + 1)],\n",
    "            test_loss_arr, label=\"Fold \" + str(fold) + \" (MAE = \" + format_mae + \")\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    ax.title.set_text('5-Fold Validation')\n",
    "    ax.legend()\n",
    "    ax.figure.savefig('Visualization/'+str(fold)+'1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
